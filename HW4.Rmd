---
title: "HW 4"
author: "Logan Schmitt"
date: "03/18/2024"
output:
  html_document:
    number_sections: yes
  pdf_document: default
---

This homework is designed to give you practice fitting a logistic regression and working with statistical/philosophical measures of fairness.  We will work with the `titanic` dataset which we have previously seen in class in connection to decision trees.  

Below I will preprocess the data precisely as we did in class.  You can simply refer to `data_train` as your training data and `data_test` as your testing data.  




```{r}

#this is all of the preprocessing done for the decision trees lecture.  

path <- 'https://raw.githubusercontent.com/guru99-edu/R-Programming/master/titanic_data.csv'
titanic <-read.csv(path)
head(titanic)

library(dplyr)

#replace ? with NA
replace_question_mark <- function(x) {
  if (is.character(x)) {
    x <- na_if(x, "?")
  }
  return(x)
}

titanic <- titanic %>%
  mutate_all(replace_question_mark)

set.seed(678)
shuffle_index <- sample(1:nrow(titanic))
head(shuffle_index)

titanic <- titanic[shuffle_index, ]
head(titanic)

library(dplyr)
# Drop variables
clean_titanic <- titanic %>%
select(-c(home.dest, cabin, name, x, ticket)) %>% 
#Convert to factor level
    mutate(pclass = factor(pclass, levels = c(1, 2, 3), labels = c('Upper', 'Middle', 'Lower')),
    survived = factor(survived, levels = c(0, 1), labels = c('No', 'Yes'))) %>%
na.omit()
#previously were characters
clean_titanic$age <- as.numeric(clean_titanic$age)
clean_titanic$fare <- as.numeric(clean_titanic$fare)
glimpse(clean_titanic)

create_train_test <- function(data, size = 0.8, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
data_train <- create_train_test(clean_titanic, 0.8, train = TRUE)
data_test <- create_train_test(clean_titanic, 0.8, train = FALSE)

```

#
Create a table reporting the proportion of people in the training set surviving the Titanic.  Do the same for the testing set.  Comment on whether the current training-testing partition looks suitable.  

```{r}
#Overall proportion of people who survived / did not survive the Titanic
round(prop.table(table(clean_titanic$survived)),2)
#Training set table
round(prop.table(table(data_train$survived)),2)
#Testing set table
round(prop.table(table(data_test$survived)),2)
```

*Logan Input:* In the training set, roughly 40% of the passengers survived. In the testing set, roughly 44% of the passengers survived. Since the testing set proportion is similar to the training set proportion (which is representative of the overall dataset), the current training-testing partition looks suitable.

#
Use the `glm` command to build a logistic regression on the training partition.  `survived` should be your response variable and `pclass`, `sex`, `age`, `sibsp`, and `parch` should be your response variables.  

```{r}
head(data_train)
model = glm(survived ~ pclass+sex+age+sibsp+parch, family = binomial(link="logit"), data = data_train)
model
```

We would now like to test whether this classifier is *fair* across the sex subgroups.  It was reported that women and children were prioritized on the life-boats and as a result survived the incident at a much higher rate.  Let us see if our model is able to capture this fact.  

#

Subset your test data into a male group and a female group.  Then, use the `predict` function on the male testing group to come up with predicted probabilities of surviving the Titanic for each male in the testing set.  Do the same for the female testing group.  

```{r}
#Subsetting testing data into a male / female group:
male_data_test = data_test %>%
  filter(sex=="male")
female_data_test = data_test %>%
  filter(sex=="female")

#Predicting male testing group survival probabilities 
male_results = predict(model, newdata = male_data_test, type = 'response')

#Predicting female testing group survival probabilities
female_results = predict(model, newdata = female_data_test, type = 'response')
```

# 

Now recall that for this logistic *regression* to be a true classifier, we need to pair it with a decision boundary.  Use an `if-else` statement to translate any predicted probability in the male group greater than $0.5$ into `Yes` (as in Yes this individual is predicted to have survived).  Likewise an predicted probability less than $0.5$ should be translated into a `No`.  

Do this for the female testing group as well, and then create a confusion matrix for each of the male and female test set predictions.  You can use the `confusionMatrix` command as seen in class to expidite this process as well as provide you necessary metrics for the following questions.  

```{r}
library(caret)
#Creating decision boundary for male survival results
male_results = ifelse(male_results > 0.5,"Yes","No")
male_confusionMatrix = confusionMatrix(
  as.factor(male_results), male_data_test$survive, positive = "Yes")
male_confusionMatrix

#Creating decision boundary for female survival results
female_results = ifelse(female_results > 0.5,"Yes","No")
female_confusionMatrix = confusionMatrix(
  as.factor(female_results), female_data_test$survive, positive = "Yes")
female_confusionMatrix
```

#
We can see that indeed, at least within the testing groups, women did seem to survive at a higher proportion than men (24.8\% to 76.3\% in the testing set).  Print a summary of your trained model and interpret one of the fitted coefficients in light of the above disparity.  

```{r}
# Male survival proportions in the testing set
round(prop.table(table(male_data_test$survived)),3)
# Female survival proportions in the testing set
round(prop.table(table(female_data_test$survived)),3)
# Summary of the model
summary(model)
```

*Logan Input:* Interpreting pclassLower: for passengers with lower-class tickets, their log odds of surviving decreases by -2.404084 compared to passengers with upper-class tickets, holding all other variables constant.


#

Now let's see if our model is *fair* across this explanatory variable.  Calculate five measures (as defined in class) in this question: the Overall accuracy rate ratio between females and males, the disparate impact between females and males, the statistical parity between females and males, and the predictive equality as well as equal opportunity between females and males (collectively these last two comprise equalized odds).  Set a reasonable $\epsilon$ each time and then comment on which (if any) of these five criteria are met.  


```{r}
epsilon = 0.2
# Measure 1: the Overall accuracy rate ratio between females and males
OverallAccuracyRatioMale = (93+4) / (93+4+4+28)
OverallAccuracyRatioMale
OverallAccuracyRatioFemale = (4+59) / (4+59+15+2)
OverallAccuracyRatioFemale
# Measure 2: the disparate impact between females and males
DInumerator = (28+4) / (28+4+93+4) # Males
DIdenominator = (2+59) / (2+59+4+15) # Females
DI = DInumerator / DIdenominator
DI
# Measure 3: the statistical parity between females and males
StatParity = abs(DInumerator-DIdenominator)
StatParity
# Measure 4: the predictive equality between females and males
PEfirst = 28 / (28+93)
PEsecond = 2 / (2+4)
PredEquality = abs(PEfirst - PEsecond) # False Positive Rate
PredEquality
# Measure 5: equal opportunity between females and males
EOfirst = 4 / (4+4)
EOsecond = 59 / (59+15)
EqualOpp = abs(EOfirst - EOsecond) # True Positive Rate
EqualOpp
```

```{r}
# Testing disparate impact
DI < (1-epsilon)
# Testing statistical parity
StatParity > epsilon
# Testing predictive equality
PredEquality > epsilon
# Testing equal opportunity 
EqualOpp > epsilon
```


*Logan Input:* The overall accuracy ratio is above 70% for both classes, so this criteria indicates a relatively high overall accuracy. 
The disparate impact between females and males exists when the male survival rate divided by the female survival rate is less than 1 - epsilon. Since 0.75 is less than 0.8, disparate impact exists among the classes. 
The statistical parity between females and males exists when the absolute difference between the male and female survival rates is greater than epsilon. Since 0.79 is greater than 0.2, statistical parity exists among the classes.
The predictive equality between females and males exists when the false positive rate is greater than epsilon. Since 0.1 is not greater than 0.2, predictive equality is not violated. 
The equal opportunity between females and males when the true positive rate is greater than epsilon. Since 0.3 is  greater than 0.2, equal opportunity is violated
Here, we see overall accuracy and some criteria met, but a few statistical fairness conditions remain violated.
NOTE: In the Titanic dataset, the protected class is the female sex.

It is always important for us to interpret our results in light of the original data and the context of the analysis.  In this case, it is relevant that we are analyzing a historical event post-facto and any disparities across demographics identified are unlikely to be replicated.  So even though our model fails numerous of the statistical fairness criteria, I would argue we need not worry that our model could be misused to perpetuate discrimination in the future.  After all, this model is likely not being used to prescribe a preferred method of treatment in the future.  


#

Even so, provide a *philosophical* notion of justice or fairness that may have motivated the Titanic survivors to act as they did. Spell out what this philosophical notion or principle entails?

*Logan Input:* John Rawls emphasized the idea of "justice as fairness." His concept, essentially an extension of "justice as need," has two components. Firstly it states that some amount of difference is inherent to the world and wherever these differences exist, we as a society should allocate resources to protect the most vulnerable. Secondly, we should allocate resources under a "veil of ignorance," such that we are impartial to our own characteristics in society and don't favor one group over another in this distribution.  
Relating this philosophical notion of fairness to the Titanic, those on board determined women and children most vulnerable (one reason possibly being due to the fact that men and / or adults can survive longer without extra help). As a result, crew and passengers prioritized the lifeboats and life vests for these two groups, as it was the most "fair" way to allocate these limited resources.
